import pyspark.sql.functions as F
import pyspark.sql.types as T
import block_utils
import common.utils
from pyspark.sql import SparkSession
spark = SparkSession \
  .builder \
  .appName("superglue studio") \
  .config("spark.sql.decimalOperations.allowPrecisionLoss",False) \
  .getOrCreate()
env = {
  "datafolder": "/opt/basin/data"
}

spark.conf.set("spark.sql.execution.arrow.maxRecordsPerBatch",200)
spark.conf.set("spark.sql.parquet.columnarReaderBatchSize",200)
spark.conf.set("spark.sql.files.maxPartitionBytes", 200000)