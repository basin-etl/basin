import json

print("loading ${inputs['df']} to ${props.location}")
block_utils.load(
    spark,
    env,
    ${inputs['df']},
    "${props.connection}",
    "${props.format}",
    "${props.location}",
    json.loads("""${JSON.stringify(props.columns)}""")
)
